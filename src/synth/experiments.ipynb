{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from divexp import *\n",
    "from detect import *\n",
    "\n",
    "import numpy as np\n",
    "np.float = float\n",
    "from skmultiflow.data import ConceptDriftStream\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from wrappers import AgrawalWrapper, SEAWrapper, HyperplaneWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_drift(DataSource, drift=True, ds_kwargs={}, train_size=5_000, n_batches=50, batch_size=200, ClfModel=DecisionTreeClassifier, clf_kwargs={}):\n",
    "    tot_samples = n_batches * batch_size # total number of samples\n",
    "    position = (n_batches // 2) * batch_size # \"center\" of the drift\n",
    "    width = (n_batches // 4) * batch_size # size of the transitory\n",
    "\n",
    "    subgroup_metric = \"accuracy\"\n",
    "    overall_metric = accuracy_score\n",
    "    minsup = 0.1\n",
    "    win_size = 5\n",
    "    reference_window = (0,win_size)\n",
    "    current_window = (n_batches - win_size, n_batches)\n",
    "\n",
    "    data_source = DataSource(**ds_kwargs)\n",
    "    stream = data_source.stream\n",
    "    drift_stream = data_source.drift_stream\n",
    "\n",
    "    if drift:\n",
    "        cds = ConceptDriftStream(stream=stream, drift_stream=drift_stream, position=position, width=width)\n",
    "    else:\n",
    "        cds = ConceptDriftStream(stream=stream, drift_stream=stream, position=position, width=width) # no drift!\n",
    "\n",
    "    X_train, y_train = stream.next_sample(train_size)\n",
    "\n",
    "    clf = ClfModel(**clf_kwargs)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    df_meta = data_source.get_metadata(X_train)\n",
    "    matches = compute_matches(df_meta, minsup=minsup)\n",
    "    print(\"# FI\", len(matches.fi))\n",
    "\n",
    "    divs = []\n",
    "    matches_ts_list = []\n",
    "    scores = []\n",
    "\n",
    "    for start_ndx in range(0, tot_samples, batch_size):\n",
    "        X_batch, y_batch = cds.next_sample(batch_size)\n",
    "        \n",
    "        y_pred = clf.predict(X_batch)\n",
    "\n",
    "        # Workaround for multi-class problems -- works with accuracy!\n",
    "        y_pred = y_batch == y_pred\n",
    "        y_batch = np.ones(len(y_batch))\n",
    "\n",
    "        scores.append(overall_metric(y_batch, y_pred))\n",
    "\n",
    "        df_batch_bin = data_source.get_metadata(X_batch)\n",
    "        matches_ts = compute_matches(df_batch_bin, fi=matches.fi)\n",
    "        matches_ts = Matches(matches=matches_ts.matches.astype(int), fi=matches.fi)\n",
    "\n",
    "        divs.append(div_explorer(matches_ts, y_batch, y_pred, [subgroup_metric]))\n",
    "        matches_ts_list.append(matches_ts)\n",
    "\n",
    "    delta, t_stat = detect_singlebatch(divs, subgroup_metric, reference_window, current_window)\n",
    "\n",
    "    return delta.min(), t_stat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# FI 50\n"
     ]
    }
   ],
   "source": [
    "n_exp = {\n",
    "    True: 5, # number for \"with drift\"\n",
    "    False: 5 # number for \"without drift\"\n",
    "}\n",
    "train_size = 5_000\n",
    "\n",
    "n_batches  = 50\n",
    "batch_size = 200\n",
    "\n",
    "tstats = np.empty(sum(n_exp.values()))\n",
    "deltas = np.empty(sum(n_exp.values()))\n",
    "gt = np.empty(sum(n_exp.values()))\n",
    "\n",
    "exp_type = \"hyper\"\n",
    "\n",
    "if exp_type == \"sea\":\n",
    "    DataClass = SEAWrapper\n",
    "    data_kwargs = {\"noise_percentage\": 0.7}\n",
    "elif exp_type == \"agrawal\":\n",
    "    DataClass = AgrawalWrapper\n",
    "    data_kwargs = {\"perturbation\": 0.7}\n",
    "elif exp_type == \"hyper\":\n",
    "    DataClass = HyperplaneWrapper\n",
    "    data_kwargs = {\"noise_percentage\": 0.1}\n",
    "\n",
    "\n",
    "i = 0\n",
    "t0 = time()\n",
    "for drift in n_exp:\n",
    "    for exp in range(n_exp[drift]):\n",
    "\n",
    "        delta, tstat = train_and_drift(DataClass,\n",
    "                                       ds_kwargs={ \"random_state\": i, **data_kwargs },\n",
    "                                       drift=drift,\n",
    "                                       train_size=train_size,\n",
    "                                       n_batches=n_batches,\n",
    "                                       batch_size=batch_size,\n",
    "                                       ClfModel=DecisionTreeClassifier,\n",
    "                                       clf_kwargs={}\n",
    "        )\n",
    "\n",
    "        deltas[i] = delta\n",
    "        tstats[i] = tstat\n",
    "        gt[i] = drift\n",
    "        print(exp, drift, tstats[i], deltas[i])\n",
    "        \n",
    "        i += 1\n",
    "t1 = time()\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m----> 5\u001b[0m fpr, tpr, thresh \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr, tpr)\n\u001b[1;32m      8\u001b[0m best_thresh \u001b[38;5;241m=\u001b[39m thresh[(tpr \u001b[38;5;241m-\u001b[39m fpr)\u001b[38;5;241m.\u001b[39margmax()]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:749\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    747\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(gt, tstats)\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "best_thresh = thresh[(tpr - fpr).argmax()]\n",
    "print(best_thresh)\n",
    "plt.scatter([fpr[(tpr - fpr).argmax()]], [tpr[(tpr - fpr).argmax()]], marker='x', c='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
